{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.offline as py\n",
    "from graphviz import Digraph\n",
    "from IPython.display import display\n",
    "from plotly import graph_objects as go\n",
    "from sklearn.datasets import load_boston, load_iris\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### The maths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The decision tree is made by continuously splitting the data based on a certain feature and feature value. The feature and feature value used to split the data are chosen to increase the purity the most (or equivalently decrease the impurity the most)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let the data at node $m$ be represented by $Q$.\n",
    "\n",
    "For a split $\\theta = (j,t_m)$ consiting of feature $j$ and threshold value $t_m$ the imputiry $G$ of a split is given by\n",
    "\n",
    "$$\n",
    "G(Q,\\theta) = \n",
    "    \\frac{n_{left}}{N_m}G(Q_{left}(\\theta)) + \n",
    "    \\frac{n_{right}}{N_m}G(Q_{right}(\\theta))\n",
    "$$\n",
    "\n",
    "Where the data $(x_i,y_i)$ is in $Q_{left}$ if $x_{i,j} <= t_m$ else $(x_i,y_i)$ is in $Q_{right}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the case of classification the Gini impurity is one the most common methods of measuring the impurity of the sample.\n",
    "\n",
    "If there are a set of classes $C$ often $C=\\{0,1\\}$ then for a given data set Q the impurity is defined as \n",
    "\n",
    "$$\n",
    "G(Q) = \\sum_{c\\in{C}} p_c(1-p_c)\n",
    "$$\n",
    "where $p_c$ is the probability of class $c$ in $Q$\n",
    "$$\n",
    "p_c = \\frac{1}{N_Q}\\sum_{x\\in{Q}}\\mathbb{1}(y_{class} = c)\n",
    "$$\n",
    "Where $N_Q = |Q|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In regression, with a continuous target variable (y), the mean square error is often used as the impurity.\n",
    "\n",
    "$$\n",
    "G(Q) = \\frac{1}{N_Q}\\sum_{y_i\\in Q}(y_i - \\bar{y})^{2}\n",
    "$$\n",
    "where $\\bar{y}$ is the mean value of $y$ in the node\n",
    "$$\n",
    "\\bar{y} = \\frac{1}{N_Q}\\sum_{y_i\\in Q}y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Define the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:decision_tree:New logger with name decision_tree\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig()\n",
    "logger = logging.getLogger('decision_tree')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info(f'New logger with name {logger.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class TreeNode():\n",
    "\n",
    "    count = itertools.count()\n",
    "\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 max_depth,\n",
    "                 min_samples_split,\n",
    "                 min_samples_leaf,\n",
    "                 n_classes=2,\n",
    "                 max_features=None,\n",
    "                 depth=0,\n",
    "                 impurity='gini',\n",
    "                 is_classifier=True):\n",
    "        \"\"\"\n",
    "        A single node in a decision tree\n",
    "\n",
    "        After recursive splitting of the input data, a given node \n",
    "        represents one split of the tree if it is not a leaf node. The\n",
    "        leaf node stores the training samples in that leaf to be used \n",
    "        for prediction. \n",
    "        The splitting nodes record the feature to split on as attribute \n",
    "        self.best_feature_index and the splitting value as attribute\n",
    "        self.best_feature_split_val\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        data: numpy.ndarray\n",
    "            The input data with shape (m samples, n features + 1 target)\n",
    "            Note the last column of the data are the target values\n",
    "        max_depth: int\n",
    "            The maximum depth allowed when \"growing\" a tree\n",
    "        min_samples_split: int\n",
    "            The minimum number of samples required to allow a split at\n",
    "            a the node\n",
    "        min_samples_leaf: int\n",
    "            The minimum number of samples allowed in a leaf. A split\n",
    "            candidate leading to less samples in a node than the\n",
    "            min_samples_leaf will be rejected\n",
    "        n_classes: int, optional, default 2\n",
    "            Number of classes in a classification setting. Ignored when\n",
    "            self.is_classifier = False\n",
    "        max_features: int, optional, default None\n",
    "            If set to 'sqrt' then only a random subset of features are\n",
    "            used to split at the node, the number of features used in\n",
    "            this case is sqrt(n_features).\n",
    "            Else all the features are considered when splitting at this\n",
    "            node\n",
    "        depth: int, optional, default 0\n",
    "            The depth of the node in the tree\n",
    "        impurity: str, optional, default 'gini'\n",
    "            The impurity measure to use when splitting at the node.\n",
    "            I have currently only implemented two\n",
    "            'gini' - Uses the gini impurity (for classification)\n",
    "            'mse' - Uses the mean square error - equal to variance (for\n",
    "            regression)\n",
    "        is_classifier: bool, optional, default True\n",
    "            Is the tree node used as part of a classification problem\n",
    "            or a regression problem. Should be set to True if\n",
    "            classification, False if regression\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.n_classes = n_classes\n",
    "        self.max_features = max_features\n",
    "        self.depth = depth\n",
    "        self.impurity = impurity\n",
    "        self.is_classifier = is_classifier\n",
    "\n",
    "        self.data_shape = data.shape\n",
    "        self.split_attempted = False\n",
    "        self.best_split_impurity = None\n",
    "        self.best_feature_index = None\n",
    "        self.best_feature_split_val = None\n",
    "        self.is_leaf = False\n",
    "        self.node_impurity = self.calculate_impurity([data[:, -1]])\n",
    "        self.value = self._init_value(data)\n",
    "        self.id = str(next(self.count))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f'<TreeNode '\n",
    "            f'depth:{self.depth} '\n",
    "            f'node_impurity:{self.node_impurity:.2f} '\n",
    "            f'samples:{self.data_shape[0]} '\n",
    "            f'{\"ðŸŒ³\" if self.is_root else \"\"}'\n",
    "            f'{\"ðŸ\" if self.is_leaf else \"\"}'\n",
    "            f'>')\n",
    "\n",
    "    @property\n",
    "    def is_root(self):\n",
    "        return self.depth == 0\n",
    "\n",
    "    def info(self):\n",
    "        return dict(\n",
    "            data_shape=self.data_shape,\n",
    "            n_classes=self.n_classes,\n",
    "            depth=self.depth,\n",
    "            min_samples_split=self.min_samples_split,\n",
    "            min_samples_leaf=self.min_samples_leaf,\n",
    "            node_impurity=self.node_impurity,\n",
    "            split_attempted=self.split_attempted,\n",
    "            best_split_impurity=self.best_split_impurity,\n",
    "            best_feature_index=self.best_feature_index,\n",
    "            best_feature_split_val=self.best_feature_split_val,\n",
    "            is_root=self.is_root)\n",
    "\n",
    "    def _init_value(self, data):\n",
    "        \"\"\"  \n",
    "        Returns the terminal node value based on the input data\n",
    "\n",
    "        For a classifier this is the class_counts.\n",
    "        For a regressor this is the average y value. \n",
    "\n",
    "        Note this value can be access at a splitting node to see what\n",
    "        the prediction would have been at that level of the tree\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        data: numpy.ndarray\n",
    "            The input data with shape (m samples, n features + 1 target)\n",
    "            Note the last column of the data are the target values\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        numpy.ndarray or float:\n",
    "            Class counts if classifier, else mean of target values \n",
    "        \"\"\"\n",
    "        if self.is_classifier:\n",
    "            return np.bincount(\n",
    "                data[:, -1].astype(int),\n",
    "                minlength=self.n_classes)\n",
    "        else:\n",
    "            return np.mean(data[:, -1])\n",
    "\n",
    "    def split(self, feature_index, feature_split_val, only_y=True):\n",
    "        \"\"\"  \n",
    "        Splits self.data on feature with index feature_index using\n",
    "        feature_split_val.\n",
    "\n",
    "        Each sample is included in left output if the feature value for\n",
    "        the sample is less than or equal to the feature_split_val else \n",
    "        it is included in the right output\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        feature_index: int\n",
    "            Index of the feature (column) in self.data\n",
    "        feature_split_val: float\n",
    "            Feature value to use when splitting data\n",
    "        only_y: bool, optional, default True\n",
    "            Return only the y values in left and right - this is used \n",
    "            when checking candidate split purity increase\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        (numpy.ndarray, numpy.ndarray):\n",
    "            left and right splits of self.data\n",
    "        \"\"\"\n",
    "        assert feature_index in range(self.data.shape[1])\n",
    "        if only_y:\n",
    "            select = -1\n",
    "        else:\n",
    "            select = slice(None)\n",
    "        left_mask = self.data[:, feature_index] <= feature_split_val\n",
    "        right_mask = ~ left_mask\n",
    "        left = self.data[left_mask, select]\n",
    "        right = self.data[right_mask, select]\n",
    "        logger.debug(\n",
    "            f'Splitting on feature_index {feature_index} with '\n",
    "            f'feature_split_val = {feature_split_val} creates left '\n",
    "            f'with shape {left.shape} and right with '\n",
    "            f'shape {right.shape}')\n",
    "        return left, right\n",
    "\n",
    "    def gini_impurity(self, groups):\n",
    "        \"\"\"  \n",
    "        Calculate the Gini impurity for groups of values\n",
    "\n",
    "        The impurity returned is the weighted average of the impurity\n",
    "        of the groups.\n",
    "\n",
    "        You can think of gini impurity as the probability of incorrectly\n",
    "        predicting a random sample from a group if the prediction was\n",
    "        made based purely on the distribution of class labels in the\n",
    "        group\n",
    "\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        groups: tuple\n",
    "            The groups tuple is made up of arrays of values. It is \n",
    "            often called with groups = (left, right) to find the purity\n",
    "            of the candidate split\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        float:\n",
    "            Gini impurity\n",
    "        \"\"\"\n",
    "        gini = 0\n",
    "        total_samples = sum(group.shape[0] for group in groups)\n",
    "        for i, group in enumerate(groups):\n",
    "            group = group.astype(int)\n",
    "            class_counts = np.bincount(group, minlength=self.n_classes)\n",
    "            group_size = class_counts.sum()\n",
    "            class_probs = class_counts / group_size\n",
    "            unique_classes = np.count_nonzero(class_counts)\n",
    "            group_gini = (class_probs * (1 - class_probs)).sum()\n",
    "            gini += group_gini * (group_size / total_samples)\n",
    "            logger.debug(\n",
    "                f'Group {i} has size {group.shape[0]} with '\n",
    "                f'{unique_classes} unique classes '\n",
    "                f'with Gini index {group_gini:.3}')\n",
    "        return gini\n",
    "\n",
    "    def mean_square_impurity(self, groups):\n",
    "        \"\"\"  \n",
    "        Calculates the mean square error impurity\n",
    "\n",
    "        The mse impurity is the weighted average of the group variances\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        groups: tuple\n",
    "            The groups tuple is made up of arrays of values. It is \n",
    "            often called with groups = (left, right) to find the purity\n",
    "            of the candidate split\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        float:\n",
    "            Mean square error impurity\n",
    "        \"\"\"\n",
    "        mean_square_error = 0\n",
    "        total_samples = sum(group.shape[0] for group in groups)\n",
    "        for i, group in enumerate(groups):\n",
    "            group_size = group.shape[0]\n",
    "            group_mean = np.mean(group)\n",
    "            group_mean_square_error = np.mean((group - group_mean) ** 2)\n",
    "            mean_square_error += group_mean_square_error * \\\n",
    "                (group_size / total_samples)\n",
    "            logger.debug(\n",
    "                f'Group {i} has size {group.shape[0]} with '\n",
    "                f'with MSE impurity {group_mean_square_error:.3}')\n",
    "        logger.debug(f'MSE candidate {mean_square_error}')\n",
    "        return mean_square_error\n",
    "\n",
    "    def calculate_impurity(self, groups):\n",
    "        \"\"\"  \n",
    "        Calculates impurity based on self.impurity setting\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        groups: tuple\n",
    "            The groups tuple is made up of arrays of values. It is \n",
    "            often called with groups = (left, right) to find the purity\n",
    "            of the candidate split\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        float:\n",
    "            Mean square error of groups if self.impurity = 'mse'\n",
    "            Gini impurity of groups if self.impurity = 'mse'\n",
    "        \"\"\"\n",
    "        if self.impurity == 'gini':\n",
    "            return self.gini_impurity(groups)\n",
    "        elif self.impurity == 'mse':\n",
    "            return self.mean_square_impurity(groups)\n",
    "\n",
    "    def check_split(self, feature_index, feature_split_val):\n",
    "        \"\"\"  \n",
    "        Updates best split if candidate split is better\n",
    "\n",
    "        Splits the data in groups using self.split. Checks min samples\n",
    "        leaf condition after split. Calculates impurity of the split\n",
    "        then if impurity is less than best split already found and less\n",
    "        than the current node impurity the best_feature_index, the \n",
    "        best_feature_split_val and the best_split_impurity values are\n",
    "        updated.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        feature_index: int\n",
    "            Index of the feature (column) in self.data\n",
    "        feature_split_val: float\n",
    "            Feature value to use when splitting data\n",
    "        \"\"\"\n",
    "        groups = self.split(feature_index, feature_split_val)\n",
    "        if any(len(group) < self.min_samples_leaf for group in groups):\n",
    "            logger.debug(\n",
    "                f\"Can't split node on feature {feature_index} with split \"\n",
    "                f\"val {feature_split_val} due to min_samples_leaf condition\")\n",
    "            return None\n",
    "        split_impurity = self.calculate_impurity(groups)\n",
    "        best_current_impurity = (\n",
    "            10**10 if self.best_split_impurity is None\n",
    "            else self.best_split_impurity)\n",
    "        if ((split_impurity < best_current_impurity) and\n",
    "                (split_impurity < self.node_impurity)):\n",
    "            logger.debug(\n",
    "                f'Found new best split with feature_split_val='\n",
    "                f'{feature_split_val} for feature_index = {feature_index} '\n",
    "                f'and split_impurity = {split_impurity:.2f}')\n",
    "            self.best_feature_index = feature_index\n",
    "            self.best_feature_split_val = feature_split_val\n",
    "            self.best_split_impurity = split_impurity\n",
    "\n",
    "    def find_best_split(self):\n",
    "        \"\"\"\n",
    "        Finds best split at the node\n",
    "\n",
    "        Loops through each feature and each unique value of that feature\n",
    "        checking for the best candidate split (i.e. the split that \n",
    "        reduces the impurity the most)\n",
    "\n",
    "        The function first checks if we have reached the max depth or if\n",
    "        self.data < self.min_samples_split. In either case no further\n",
    "        split is allowed and the function returns\n",
    "\n",
    "        All features are considered unless self.max_features == 'sqrt'\n",
    "        in which case a random subset of features are used of size\n",
    "        sqrt(n_features)\n",
    "        \"\"\"\n",
    "        if self.depth == self.max_depth:\n",
    "            return\n",
    "        if self.data.shape[0] < self.min_samples_split:\n",
    "            logger.info(f\"{self} can't split as samples < min_samples_split\")\n",
    "            return None\n",
    "        if self.node_impurity == 0:\n",
    "            logger.info(f\"Can't improve as node pure\")\n",
    "            return None\n",
    "        n_features = self.data.shape[1] - 1\n",
    "        all_feature_indices = np.arange(n_features)\n",
    "        if self.max_features == 'sqrt':\n",
    "            features_to_check = np.random.choice(\n",
    "                all_feature_indices,\n",
    "                size=np.sqrt(n_features).astype(int))\n",
    "        else:\n",
    "            features_to_check = all_feature_indices\n",
    "        logger.info(f'Checking features {features_to_check}')\n",
    "        for feature_index in features_to_check:\n",
    "            for feature_split_val in np.unique(self.data[:, feature_index]):\n",
    "                self.check_split(feature_index, feature_split_val)\n",
    "        self.split_attempted = True\n",
    "\n",
    "    def recursive_split(self):\n",
    "        \"\"\"  \n",
    "        Recursively grows tree by splitting to reduce impurity the most\n",
    "\n",
    "        The function finds the best split using the find_best_split\n",
    "        method. If there was a split found two nodes are created - left\n",
    "        and right. Finally the recursive_split method is called on each\n",
    "        of the new nodes.\n",
    "\n",
    "        Note the depth of the children node is incremented, otherwise\n",
    "        the node settings such as min_samples_split are passed to the\n",
    "        children nodes\n",
    "        \"\"\"\n",
    "        self.find_best_split()\n",
    "        if self.best_feature_index is not None:\n",
    "            logger.info(f'Splitting tree on feature_index '\n",
    "                        f'{self.best_feature_index} and feature_split_val '\n",
    "                        f'{self.best_feature_split_val:.2f}')\n",
    "            left, right = self.split(\n",
    "                feature_index=self.best_feature_index,\n",
    "                feature_split_val=self.best_feature_split_val,\n",
    "                only_y=False)\n",
    "            del self.data\n",
    "            self.left = TreeNode(\n",
    "                data=left,\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                n_classes=self.n_classes,\n",
    "                max_features=self.max_features,\n",
    "                depth=self.depth + 1,\n",
    "                impurity=self.impurity,\n",
    "                is_classifier=self.is_classifier)\n",
    "            self.right = TreeNode(\n",
    "                data=right,\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                n_classes=self.n_classes,\n",
    "                max_features=self.max_features,\n",
    "                depth=self.depth + 1,\n",
    "                impurity=self.impurity,\n",
    "                is_classifier=self.is_classifier)\n",
    "            self.left.recursive_split()\n",
    "            self.right.recursive_split()\n",
    "        else:\n",
    "            logger.info('Reached max depth or no splits reduce impurity')\n",
    "            self.is_leaf = True\n",
    "\n",
    "    def walk_depth_first(self, only_leaves=True):\n",
    "        \"\"\"  \n",
    "        Generator traversing of all nodes below and including this node\n",
    "\n",
    "        Depth first so visiting children before siblings\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        only_leaves: bool, optional, default True\n",
    "            Only return leaf nodes\n",
    "\n",
    "        Yields:\n",
    "            TreeNode: each node in tree\n",
    "        \"\"\"\n",
    "        if self.is_leaf:\n",
    "            yield self\n",
    "        else:\n",
    "            if not only_leaves:\n",
    "                yield self\n",
    "            for node in (self.left, self.right):\n",
    "                yield from node.walk_depth_first(only_leaves)\n",
    "\n",
    "    def walk_breadth_first(self, layer=None):\n",
    "        \"\"\"  \n",
    "        Generator traversing of all nodes below and including this node\n",
    "\n",
    "        Breadth first so visiting siblings before children\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        only_leaves: bool, optional, default True\n",
    "            Only return leaf nodes\n",
    "\n",
    "        Yields:\n",
    "            TreeNode: each node in tree\n",
    "        \"\"\"\n",
    "        if layer is None:\n",
    "            layer = [self]\n",
    "        for node in layer:\n",
    "            yield node\n",
    "        new_layer = [\n",
    "            child\n",
    "            for node_children in [[node.left, node.right]\n",
    "                                  for node in layer if not node.is_leaf]\n",
    "            for child in node_children]\n",
    "        if new_layer:\n",
    "            yield from self.walk_breadth_first(new_layer)\n",
    "\n",
    "    def print_tree(self):\n",
    "        \"\"\"  \n",
    "        prints ascii representation of tree below this node\n",
    "        \"\"\"\n",
    "        for node in self.walk_depth_first(only_leaves=False):\n",
    "            print('--' * node.depth + str(node))\n",
    "\n",
    "    def predict_row_proba(self, row):\n",
    "        \"\"\"\n",
    "        Predicts class probabilities for input row by walking the tree\n",
    "        and returning the leaf node class probabilities\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        row: numpy.ndarray\n",
    "            Input row, shape (n features,)\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        numpy.ndarray:\n",
    "            Class probabilities, shape (n classes, )\n",
    "        \"\"\"\n",
    "        if self.is_leaf:\n",
    "            group_size = self.value.sum()\n",
    "            class_probs = self.value / group_size\n",
    "            return class_probs\n",
    "        elif row[self.best_feature_index] <= self.best_feature_split_val:\n",
    "            return self.left.predict_row_proba(row)\n",
    "        else:\n",
    "            return self.right.predict_row_proba(row)\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "        \"\"\"Predicts class probabilities for input data\n",
    "\n",
    "        Predicts class probabilities for each row in data by walking the\n",
    "        tree and returning the leaf node class probabilities\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        data: numpy.ndarray\n",
    "            The input data with shape (m samples, n features)\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        numpy.ndarray:\n",
    "            Predicted sample class probabilities, \n",
    "            shape (m samples, n classes)\n",
    "        \"\"\"\n",
    "        if not self.is_classifier:\n",
    "            raise Exception('Not a classifier')\n",
    "        if len(data.shape) == 2:\n",
    "            return np.stack([self.predict_row_proba(row)\n",
    "                             for row in data])\n",
    "        else:\n",
    "            return self.predict_row_proba(data)\n",
    "\n",
    "    def predict_regressor_row(self, row):\n",
    "        \"\"\"\n",
    "        Predicts target value for input row by walking the tree\n",
    "        and returning the leaf node value\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        row: numpy.ndarray\n",
    "            Input row, shape (n features,)\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        float:\n",
    "            Predicted target value\n",
    "        \"\"\"\n",
    "        if self.is_leaf:\n",
    "            return self.value\n",
    "        elif row[self.best_feature_index] <= self.best_feature_split_val:\n",
    "            return self.left.predict_regressor_row(row)\n",
    "        else:\n",
    "            return self.right.predict_regressor_row(row)\n",
    "\n",
    "    def predict_regressor(self, data):\n",
    "        \"\"\"  \n",
    "        Predicts target values for each row in data by walking the\n",
    "        tree and returning the leaf node values\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        data: numpy.ndarray\n",
    "            The input data with shape (m samples, n features)\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        numpy.ndarray:\n",
    "            Predicted target values, shape (m samples, 1)\n",
    "        \"\"\"\n",
    "        if len(data.shape) == 2:\n",
    "            return np.stack([self.predict_regressor_row(row)\n",
    "                             for row in data])\n",
    "        else:\n",
    "            return self.predict_regressor_row(data)\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"Predicts target values or class labels for classification\n",
    "\n",
    "        Predicts target values/class for each row in data by walking the\n",
    "        tree and returning the leaf node value for regression or the \n",
    "        class with the largest predicted probability for classification\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        data: numpy.ndarray\n",
    "            The input data with shape (m samples, n features)\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        numpy.ndarray:\n",
    "            Predicted target values or class labels for classification\n",
    "        \"\"\"\n",
    "        if self.is_classifier:\n",
    "            return np.argmax(self.predict_proba(data), axis=-1)\n",
    "        else:\n",
    "            return self.predict_regressor(data)\n",
    "\n",
    "    def dot(self,\n",
    "            feature_names,\n",
    "            samples=True,\n",
    "            impurity=True,\n",
    "            value=True):\n",
    "        \"\"\"  \n",
    "        Returns Digraph visualizing the tree below this node\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        feature_names: list[str]\n",
    "            List of feature names\n",
    "        samples: bool, optional, default True\n",
    "            Whether to display the number of samples on this node\n",
    "        impurity: bool, optional, default True\n",
    "            Whether to display the impurity value on this node\n",
    "        value: bool, optional, default True\n",
    "            Whether to dispaly the value on this node\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        graphviz.Digraph:\n",
    "            dot for tree diagram visual\n",
    "        \"\"\"\n",
    "        dot = Digraph(\n",
    "            comment='Decsion Tree',\n",
    "            node_attr=dict(shape=\"rectangle\",\n",
    "                           style=\"rounded\",\n",
    "                           fillcolor=\"#028d35\"))\n",
    "        for i, node in enumerate(self.walk_breadth_first()):\n",
    "            label = \"\"\n",
    "            if not node.is_leaf:\n",
    "                label += (\n",
    "                    f'{feature_names[node.best_feature_index]} <= '\n",
    "                    f'{node.best_feature_split_val}\\n')\n",
    "                dot.edge(node.id, node.left.id)\n",
    "                dot.edge(node.id, node.right.id)\n",
    "            if samples:\n",
    "                label += f'Samples = {node.data_shape[0]}\\n'\n",
    "            if impurity:\n",
    "                label += f'Impurity = {node.node_impurity:.2f}\\n'\n",
    "            if value:\n",
    "                if self.is_classifier:\n",
    "                    label += f'Class counts = {str(node.value)}\\n'\n",
    "                else:\n",
    "                    label += f'Average y = {node.value:.2f}\\n'\n",
    "            dot.node(name=node.id, label=label)\n",
    "        return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTree():\n",
    "\n",
    "    def __init__(self,\n",
    "                 max_depth=2,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 n_classes=2,\n",
    "                 max_features=None,\n",
    "                 impurity='gini',\n",
    "                 is_classifier=True):\n",
    "        \"\"\"Decision tree model\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        max_depth: int\n",
    "            The maximum depth allowed when \"growing\" a tree\n",
    "        min_samples_split: int\n",
    "            The minimum number of samples required to allow a split at\n",
    "            a the node\n",
    "        min_samples_leaf: int\n",
    "            The minimum number of samples allowed in a leaf. A split\n",
    "            candidate leading to less samples in a node than the\n",
    "            min_samples_leaf will be rejected\n",
    "        n_classes: int, optional, default 2\n",
    "            Number of classes in a classification setting. Ignored when\n",
    "            self.is_classifier = False\n",
    "        max_features: int, optional, default None\n",
    "            If set to 'sqrt' then only a random subset of features are\n",
    "            used to split at each node, the number of features used in\n",
    "            this case is sqrt(n_features).\n",
    "            Else all the features are considered when splitting at each\n",
    "            node\n",
    "        impurity: str, optional, default 'gini'\n",
    "            The impurity measure to use when splitting at each node.\n",
    "            I have currently only implemented two\n",
    "            'gini' - Uses the gini impurity (for classification)\n",
    "            'mse' - Uses the mean square error - equal to variance (for\n",
    "            regression)\n",
    "        is_classifier: bool, optional, default True\n",
    "            Is the model used as part of a classification problem\n",
    "            or a regression problem. Should be set to True if\n",
    "            classification, False if regression\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.n_classes = n_classes\n",
    "        self.max_features = max_features\n",
    "        self.impurity = impurity\n",
    "        self.is_classifier = is_classifier\n",
    "\n",
    "        self.is_fitted = False\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fits the decision tree model\n",
    "\n",
    "        The tree is fitted by instantiaing a root TreeNode instance and\n",
    "        then calling the recursive_split method. This iteratively grows\n",
    "        the tree by finding the best split to reduce the impurity the\n",
    "        most.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X: numpy.ndarray\n",
    "            Training data, shape (m samples, n features)\n",
    "        y: numpy.ndarray\n",
    "            Target values, shape (m samples, n features)\n",
    "            If classifier with n_classes the values are assumed to be in\n",
    "            0, ..., n-1\n",
    "        \"\"\"\n",
    "        y_shape = (X.shape[0], 1)\n",
    "        data = np.concatenate((X, y.reshape(y_shape)), axis=1)\n",
    "        self.tree = TreeNode(\n",
    "            data=data,\n",
    "            max_depth=self.max_depth,\n",
    "            min_samples_split=self.min_samples_split,\n",
    "            min_samples_leaf=self.min_samples_leaf,\n",
    "            n_classes=self.n_classes,\n",
    "            max_features=self.max_features,\n",
    "            impurity=self.impurity,\n",
    "            is_classifier=self.is_classifier)\n",
    "        self.tree.recursive_split()\n",
    "        self.is_fitted = True\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"Predicts target values or class labels for classification\n",
    "\n",
    "        Predicts target values/class for each row in data by walking the\n",
    "        tree and returning the leaf node value for regression or the \n",
    "        class with the largest predicted probability for classification\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        data: numpy.ndarray\n",
    "            The input data with shape (m samples, n features)\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        numpy.ndarray:\n",
    "            Predicted target values or class labels for classification\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise Exception('Decision tree not fitted')\n",
    "        return self.tree.predict(data)\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "        \"\"\"Predicts class probabilities for input data\n",
    "\n",
    "        Predicts class probabilities for each row in data by walking the\n",
    "        tree and returning the leaf node class probabilities\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        data: numpy.ndarray\n",
    "            The input data with shape (m samples, n features)\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        numpy.ndarray:\n",
    "            Predicted sample class probabilities, \n",
    "            shape (m samples, n classes)\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise Exception('Decision tree not fitted')\n",
    "        return self.tree.predict_proba(data)\n",
    "\n",
    "    def render(self, feature_names):\n",
    "        \"\"\"Returns Digraph visualizing the decision tree (if fitted)\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        feature_names: list[str]\n",
    "            List of feature names\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        graphviz.Digraph:\n",
    "            dot for tree diagram visual\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            print('Decision tree not fitted')\n",
    "        else:\n",
    "            return self.tree.dot(feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Decision tree classifier - Iris data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  y\n",
       "0                6.1               2.8                4.7               1.2  1\n",
       "1                5.7               3.8                1.7               0.3  0\n",
       "2                7.7               2.6                6.9               2.3  2\n",
       "3                6.0               2.9                4.5               1.5  1\n",
       "4                6.8               2.8                4.8               1.4  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "iris_df = pd.DataFrame(iris_data['data'], columns=iris_data['feature_names'])\n",
    "iris_df['y'] = iris_data['target']\n",
    "iris_df = iris_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "iris_sample = iris_df.head(5)\n",
    "iris_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Fit tree decision tree classifier and visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:decision_tree:Checking features [0 1 2 3]\n",
      "INFO:decision_tree:Splitting tree on feature_index 2 and feature_split_val 1.90\n",
      "INFO:decision_tree:Can't improve as node pure\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Checking features [0 1 2 3]\n",
      "INFO:decision_tree:Splitting tree on feature_index 3 and feature_split_val 1.70\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"418pt\" height=\"258pt\"\n",
       " viewBox=\"0.00 0.00 417.61 258.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 254)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-254 413.61,-254 413.61,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M229.91,-250C229.91,-250 94.69,-250 94.69,-250 88.69,-250 82.69,-244 82.69,-238 82.69,-238 82.69,-198 82.69,-198 82.69,-192 88.69,-186 94.69,-186 94.69,-186 229.91,-186 229.91,-186 235.91,-186 241.91,-192 241.91,-198 241.91,-198 241.91,-238 241.91,-238 241.91,-244 235.91,-250 229.91,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.3\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\">petal length (cm) &lt;= 1.9</text>\n",
       "<text text-anchor=\"middle\" x=\"162.3\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 150</text>\n",
       "<text text-anchor=\"middle\" x=\"162.3\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.67</text>\n",
       "<text text-anchor=\"middle\" x=\"162.3\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [50 50 50]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.41,-143C140.41,-143 12.19,-143 12.19,-143 6.19,-143 0.19,-137 0.19,-131 0.19,-131 0.19,-105 0.19,-105 0.19,-99 6.19,-93 12.19,-93 12.19,-93 140.41,-93 140.41,-93 146.41,-93 152.41,-99 152.41,-105 152.41,-105 152.41,-131 152.41,-131 152.41,-137 146.41,-143 140.41,-143\"/>\n",
       "<text text-anchor=\"middle\" x=\"76.3\" y=\"-127.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 50</text>\n",
       "<text text-anchor=\"middle\" x=\"76.3\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.00</text>\n",
       "<text text-anchor=\"middle\" x=\"76.3\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [50 &#160;0 &#160;0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135.09,-185.99C125.26,-174.78 114.14,-162.12 104.24,-150.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.84,-148.5 97.62,-143.29 101.58,-153.11 106.84,-148.5\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M314.41,-150C314.41,-150 182.2,-150 182.2,-150 176.2,-150 170.2,-144 170.2,-138 170.2,-138 170.2,-98 170.2,-98 170.2,-92 176.2,-86 182.2,-86 182.2,-86 314.41,-86 314.41,-86 320.41,-86 326.41,-92 326.41,-98 326.41,-98 326.41,-138 326.41,-138 326.41,-144 320.41,-150 314.41,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.3\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.7</text>\n",
       "<text text-anchor=\"middle\" x=\"248.3\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 100</text>\n",
       "<text text-anchor=\"middle\" x=\"248.3\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.50</text>\n",
       "<text text-anchor=\"middle\" x=\"248.3\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [ 0 50 50]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M189.52,-185.99C197.36,-177.06 206.01,-167.19 214.22,-157.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"217.01,-159.97 220.98,-150.14 211.75,-155.35 217.01,-159.97\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M226.41,-50C226.41,-50 98.19,-50 98.19,-50 92.19,-50 86.19,-44 86.19,-38 86.19,-38 86.19,-12 86.19,-12 86.19,-6 92.19,0 98.19,0 98.19,0 226.41,0 226.41,0 232.41,0 238.41,-6 238.41,-12 238.41,-12 238.41,-38 238.41,-38 238.41,-44 232.41,-50 226.41,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.3\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 54</text>\n",
       "<text text-anchor=\"middle\" x=\"162.3\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.17</text>\n",
       "<text text-anchor=\"middle\" x=\"162.3\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [ 0 49 &#160;5]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M218.95,-85.94C210.28,-76.77 200.79,-66.72 192.09,-57.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"194.43,-54.89 185.01,-50.03 189.34,-59.7 194.43,-54.89\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M397.41,-50C397.41,-50 269.19,-50 269.19,-50 263.19,-50 257.19,-44 257.19,-38 257.19,-38 257.19,-12 257.19,-12 257.19,-6 263.19,0 269.19,0 269.19,0 397.41,0 397.41,0 403.41,0 409.41,-6 409.41,-12 409.41,-12 409.41,-38 409.41,-38 409.41,-44 403.41,-50 397.41,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"333.3\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 46</text>\n",
       "<text text-anchor=\"middle\" x=\"333.3\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.04</text>\n",
       "<text text-anchor=\"middle\" x=\"333.3\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [ 0 &#160;1 45]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M277.32,-85.94C285.89,-76.77 295.27,-66.72 303.86,-57.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"306.59,-59.73 310.86,-50.03 301.48,-54.95 306.59,-59.73\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1224dbc90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # for small sample\n",
    "# iris_sample_vals = iris_sample.values\n",
    "# X = iris_sample_vals[:,:-1]\n",
    "# y = iris_sample_vals[:,-1]\n",
    "\n",
    "X = iris_df.values[:,:-1]\n",
    "y = iris_df.values[:,-1]\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "decision_tree = DecisionTree(n_classes=3, impurity='gini', is_classifier=True)\n",
    "decision_tree.fit(X, y)\n",
    "\n",
    "# For info or ansii tree\n",
    "# decision_tree.tree.info()\n",
    "# decision_tree.tree.print_tree()\n",
    "\n",
    "feature_names = iris_data['feature_names']\n",
    "decision_tree.render(feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Example prediction on Iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.predict(X[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0,\n",
       "       1, 2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0,\n",
       "       0, 2, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1,\n",
       "       1, 2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 1,\n",
       "       0, 2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0,\n",
       "       1, 2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0,\n",
       "       0, 1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1,\n",
       "       1, 2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2,\n",
       "       0, 2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real y values\n",
    "y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(decision_tree.predict(X) == y.astype(int)).sum() / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Compare with Sklearn on Iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"320pt\" height=\"258pt\"\n",
       " viewBox=\"0.00 0.00 319.54 258.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 254)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-254 315.54,-254 315.54,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"186.31,-250 60.23,-250 60.23,-186 186.31,-186 186.31,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.27\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\">X[2] &lt;= 2.45</text>\n",
       "<text text-anchor=\"middle\" x=\"123.27\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.667</text>\n",
       "<text text-anchor=\"middle\" x=\"123.27\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 150</text>\n",
       "<text text-anchor=\"middle\" x=\"123.27\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [50, 50, 50]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"112.31,-143 0.23,-143 0.23,-93 112.31,-93 112.31,-143\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.27\" y=\"-127.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"56.27\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 50</text>\n",
       "<text text-anchor=\"middle\" x=\"56.27\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [50, 0, 0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.07,-185.99C94.63,-175.11 86.25,-162.85 78.71,-151.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"81.41,-149.57 72.87,-143.29 75.63,-153.52 81.41,-149.57\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.26\" y=\"-163.66\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"249.81,-150 130.73,-150 130.73,-86 249.81,-86 249.81,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.27\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">X[3] &lt;= 1.75</text>\n",
       "<text text-anchor=\"middle\" x=\"190.27\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"190.27\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 100</text>\n",
       "<text text-anchor=\"middle\" x=\"190.27\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [0, 50, 50]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.47,-185.99C150.46,-177.23 157.05,-167.58 163.33,-158.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"166.22,-160.37 168.98,-150.14 160.44,-156.42 166.22,-160.37\"/>\n",
       "<text text-anchor=\"middle\" x=\"173.59\" y=\"-170.51\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"180.31,-50 68.23,-50 68.23,0 180.31,0 180.31,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"124.27\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.168</text>\n",
       "<text text-anchor=\"middle\" x=\"124.27\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 54</text>\n",
       "<text text-anchor=\"middle\" x=\"124.27\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [0, 49, 5]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167.74,-85.94C161.29,-77.04 154.24,-67.32 147.73,-58.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"150.4,-56.07 141.7,-50.03 144.73,-60.18 150.4,-56.07\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"311.31,-50 199.23,-50 199.23,0 311.31,0 311.31,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"255.27\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">gini = 0.043</text>\n",
       "<text text-anchor=\"middle\" x=\"255.27\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 46</text>\n",
       "<text text-anchor=\"middle\" x=\"255.27\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [0, 1, 45]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M212.46,-85.94C218.81,-77.04 225.75,-67.32 232.16,-58.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"235.14,-60.2 238.1,-50.03 229.44,-56.13 235.14,-60.2\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x122525e10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_decision_tree = DecisionTreeClassifier(\n",
    "    max_depth=decision_tree.max_depth,\n",
    "    min_samples_leaf=decision_tree.min_samples_leaf,\n",
    "    min_samples_split=decision_tree.min_samples_split)\n",
    "\n",
    "sk_decision_tree.fit(X, y)\n",
    "\n",
    "# Visualize the sklearn tree\n",
    "# Note - same as ours except not using midpoints between split_vals\n",
    "\n",
    "graphviz.Source(export_graphviz(sk_decision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Decision tree classifier - Titanic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Load titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_feather('../data/titanic/processed/X_train.feather')\n",
    "y_train = pd.read_feather('../data/titanic/processed/y_train.feather')\n",
    "X_test = pd.read_feather('../data/titanic/processed/X_test.feather')\n",
    "y_test = pd.read_feather('../data/titanic/processed/y_test.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Decision tree accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:decision_tree:Checking features [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "INFO:decision_tree:Splitting tree on feature_index 27 and feature_split_val 0.00\n",
      "INFO:decision_tree:Checking features [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "INFO:decision_tree:Splitting tree on feature_index 10 and feature_split_val 0.00\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Checking features [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "INFO:decision_tree:Splitting tree on feature_index 1 and feature_split_val -0.12\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 75.42%\n"
     ]
    }
   ],
   "source": [
    "# for best result use max depth = 4\n",
    "\n",
    "titanic_decision_tree = DecisionTree(max_depth=2)\n",
    "titanic_decision_tree.fit(X_train.values, y_train.values)\n",
    "y_pred = titanic_decision_tree.predict(X_test.values)\n",
    "test_acc = (y_pred == y_test.values.flatten()).sum() / len(y_test)\n",
    "print(f'Test accuracy = {test_acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Visulaise titanic decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"661pt\" height=\"258pt\"\n",
       " viewBox=\"0.00 0.00 661.36 258.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 254)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-254 657.36,-254 657.36,4 -4,4\"/>\n",
       "<!-- 5 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M395.41,-250C395.41,-250 263.2,-250 263.2,-250 257.2,-250 251.2,-244 251.2,-238 251.2,-238 251.2,-198 251.2,-198 251.2,-192 257.2,-186 263.2,-186 263.2,-186 395.41,-186 395.41,-186 401.41,-186 407.41,-192 407.41,-198 407.41,-198 407.41,-238 407.41,-238 407.41,-244 401.41,-250 395.41,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"329.3\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\">parch_mr &lt;= 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"329.3\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 712</text>\n",
       "<text text-anchor=\"middle\" x=\"329.3\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.47</text>\n",
       "<text text-anchor=\"middle\" x=\"329.3\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [444 268]</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M299.41,-150C299.41,-150 171.19,-150 171.19,-150 165.19,-150 159.19,-144 159.19,-138 159.19,-138 159.19,-98 159.19,-98 159.19,-92 165.19,-86 171.19,-86 171.19,-86 299.41,-86 299.41,-86 305.41,-86 311.41,-92 311.41,-98 311.41,-98 311.41,-138 311.41,-138 311.41,-144 305.41,-150 299.41,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"235.3\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">embarked_3 &lt;= 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"235.3\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 293</text>\n",
       "<text text-anchor=\"middle\" x=\"235.3\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.43</text>\n",
       "<text text-anchor=\"middle\" x=\"235.3\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [ 90 203]</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M299.56,-185.99C290.9,-176.97 281.34,-166.99 272.29,-157.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.62,-154.94 265.18,-150.14 269.57,-159.78 274.62,-154.94\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M505.01,-150C505.01,-150 341.6,-150 341.6,-150 335.6,-150 329.6,-144 329.6,-138 329.6,-138 329.6,-98 329.6,-98 329.6,-92 335.6,-86 341.6,-86 341.6,-86 505.01,-86 505.01,-86 511.01,-86 517.01,-92 517.01,-98 517.01,-98 517.01,-138 517.01,-138 517.01,-144 511.01,-150 505.01,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"423.3\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">fare &lt;= &#45;0.1220086178826921</text>\n",
       "<text text-anchor=\"middle\" x=\"423.3\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 419</text>\n",
       "<text text-anchor=\"middle\" x=\"423.3\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.26</text>\n",
       "<text text-anchor=\"middle\" x=\"423.3\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [354 &#160;65]</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M359.05,-185.99C367.7,-176.97 377.27,-166.99 386.32,-157.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"389.04,-159.78 393.43,-150.14 383.99,-154.94 389.04,-159.78\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.41,-50C140.41,-50 12.19,-50 12.19,-50 6.19,-50 0.19,-44 0.19,-38 0.19,-38 0.19,-12 0.19,-12 0.19,-6 6.19,0 12.19,0 12.19,0 140.41,0 140.41,0 146.41,0 152.41,-6 152.41,-12 152.41,-12 152.41,-38 152.41,-38 152.41,-44 146.41,-50 140.41,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"76.3\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 155</text>\n",
       "<text text-anchor=\"middle\" x=\"76.3\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.19</text>\n",
       "<text text-anchor=\"middle\" x=\"76.3\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [ 16 139]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.03,-85.94C163.56,-75.94 144.28,-64.91 127.08,-55.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"128.71,-51.96 118.29,-50.03 125.23,-58.04 128.71,-51.96\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M300.41,-50C300.41,-50 182.2,-50 182.2,-50 176.2,-50 170.2,-44 170.2,-38 170.2,-38 170.2,-12 170.2,-12 170.2,-6 176.2,0 182.2,0 182.2,0 300.41,0 300.41,0 306.41,0 312.41,-6 312.41,-12 312.41,-12 312.41,-38 312.41,-38 312.41,-44 306.41,-50 300.41,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"241.3\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 138</text>\n",
       "<text text-anchor=\"middle\" x=\"241.3\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.50</text>\n",
       "<text text-anchor=\"middle\" x=\"241.3\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [74 64]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;9 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>6&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M237.35,-85.94C237.9,-77.59 238.5,-68.52 239.06,-60.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"242.55,-60.24 239.72,-50.03 235.57,-59.78 242.55,-60.24\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M481.41,-50C481.41,-50 353.19,-50 353.19,-50 347.19,-50 341.19,-44 341.19,-38 341.19,-38 341.19,-12 341.19,-12 341.19,-6 347.19,0 353.19,0 353.19,0 481.41,0 481.41,0 487.41,0 493.41,-6 493.41,-12 493.41,-12 493.41,-38 493.41,-38 493.41,-44 487.41,-50 481.41,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"417.3\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 321</text>\n",
       "<text text-anchor=\"middle\" x=\"417.3\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.19</text>\n",
       "<text text-anchor=\"middle\" x=\"417.3\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [286 &#160;35]</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;10 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>7&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M421.26,-85.94C420.71,-77.59 420.11,-68.52 419.55,-60.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"423.04,-59.78 418.89,-50.03 416.05,-60.24 423.04,-59.78\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M641.41,-50C641.41,-50 523.2,-50 523.2,-50 517.2,-50 511.2,-44 511.2,-38 511.2,-38 511.2,-12 511.2,-12 511.2,-6 517.2,0 523.2,0 523.2,0 641.41,0 641.41,0 647.41,0 653.41,-6 653.41,-12 653.41,-12 653.41,-38 653.41,-38 653.41,-44 647.41,-50 641.41,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"582.3\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 98</text>\n",
       "<text text-anchor=\"middle\" x=\"582.3\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 0.42</text>\n",
       "<text text-anchor=\"middle\" x=\"582.3\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Class counts = [68 30]</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;11 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>7&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M477.58,-85.94C495.05,-75.94 514.32,-64.91 531.53,-55.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"533.38,-58.04 540.32,-50.03 529.9,-51.96 533.38,-58.04\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1263e96d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_features = list(X_train.columns)\n",
    "titanic_decision_tree.render(titanic_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Decision tree regressor - Boston housing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Load boston data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.416</td>\n",
       "      <td>84.1</td>\n",
       "      <td>2.6463</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>395.50</td>\n",
       "      <td>9.04</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05644</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>6.758</td>\n",
       "      <td>32.9</td>\n",
       "      <td>4.0776</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>3.53</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>6.065</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>390.91</td>\n",
       "      <td>5.52</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.09017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.3682</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>385.09</td>\n",
       "      <td>17.27</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS   RAD    TAX  \\\n",
       "0  0.09178   0.0   4.05   0.0  0.510  6.416  84.1  2.6463   5.0  296.0   \n",
       "1  0.05644  40.0   6.41   1.0  0.447  6.758  32.9  4.0776   4.0  254.0   \n",
       "2  0.10574   0.0  27.74   0.0  0.609  5.983  98.8  1.8681   4.0  711.0   \n",
       "3  0.09164   0.0  10.81   0.0  0.413  6.065   7.8  5.2873   4.0  305.0   \n",
       "4  5.09017   0.0  18.10   0.0  0.713  6.297  91.8  2.3682  24.0  666.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT     y  \n",
       "0     16.6  395.50   9.04  23.6  \n",
       "1     17.6  396.90   3.53  32.4  \n",
       "2     20.1  390.11  18.07  13.6  \n",
       "3     19.2  390.91   5.52  22.8  \n",
       "4     20.2  385.09  17.27  16.1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data = load_boston()\n",
    "boston_df = pd.DataFrame(boston_data['data'], columns=boston_data['feature_names'])\n",
    "boston_df['y'] = boston_data['target']\n",
    "boston_df = boston_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "boston_sample = boston_df.head(5)\n",
    "boston_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Fit decision tree on Boston data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:decision_tree:Checking features [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "INFO:decision_tree:Splitting tree on feature_index 5 and feature_split_val 6.83\n",
      "INFO:decision_tree:Checking features [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "INFO:decision_tree:Splitting tree on feature_index 12 and feature_split_val 14.36\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Checking features [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "INFO:decision_tree:Splitting tree on feature_index 5 and feature_split_val 7.42\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n",
      "INFO:decision_tree:Reached max depth or no splits reduce impurity\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"538pt\" height=\"258pt\"\n",
       " viewBox=\"0.00 0.00 538.28 258.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 254)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-254 534.28,-254 534.28,4 -4,4\"/>\n",
       "<!-- 12 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.42,-250C312.42,-250 216.86,-250 216.86,-250 210.86,-250 204.86,-244 204.86,-238 204.86,-238 204.86,-198 204.86,-198 204.86,-192 210.86,-186 216.86,-186 216.86,-186 312.42,-186 312.42,-186 318.42,-186 324.42,-192 324.42,-198 324.42,-198 324.42,-238 324.42,-238 324.42,-244 318.42,-250 312.42,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.64\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\">RM &lt;= 6.833</text>\n",
       "<text text-anchor=\"middle\" x=\"264.64\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 404</text>\n",
       "<text text-anchor=\"middle\" x=\"264.64\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 88.13</text>\n",
       "<text text-anchor=\"middle\" x=\"264.64\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 22.71</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244.42,-150C244.42,-150 148.86,-150 148.86,-150 142.86,-150 136.86,-144 136.86,-138 136.86,-138 136.86,-98 136.86,-98 136.86,-92 142.86,-86 148.86,-86 148.86,-86 244.42,-86 244.42,-86 250.42,-86 256.42,-92 256.42,-98 256.42,-98 256.42,-138 256.42,-138 256.42,-144 250.42,-150 244.42,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">LSTAT &lt;= 14.36</text>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 331</text>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 41.74</text>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 19.72</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243.12,-185.99C237.05,-177.23 230.35,-167.58 223.98,-158.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"226.82,-156.36 218.25,-150.14 221.07,-160.35 226.82,-156.36\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M381.42,-150C381.42,-150 285.86,-150 285.86,-150 279.86,-150 273.86,-144 273.86,-138 273.86,-138 273.86,-98 273.86,-98 273.86,-92 279.86,-86 285.86,-86 285.86,-86 381.42,-86 381.42,-86 387.42,-86 393.42,-92 393.42,-98 393.42,-98 393.42,-138 393.42,-138 393.42,-144 387.42,-150 381.42,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">RM &lt;= 7.42</text>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 73</text>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 74.07</text>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 36.27</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M286.47,-185.99C292.64,-177.23 299.43,-167.58 305.9,-158.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.82,-160.33 311.71,-150.14 303.09,-156.3 308.82,-160.33\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.42,-50C107.42,-50 11.86,-50 11.86,-50 5.86,-50 -0.14,-44 -0.14,-38 -0.14,-38 -0.14,-12 -0.14,-12 -0.14,-6 5.86,0 11.86,0 11.86,0 107.42,0 107.42,0 113.42,0 119.42,-6 119.42,-12 119.42,-12 119.42,-38 119.42,-38 119.42,-44 113.42,-50 107.42,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"59.64\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 194</text>\n",
       "<text text-anchor=\"middle\" x=\"59.64\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 29.34</text>\n",
       "<text text-anchor=\"middle\" x=\"59.64\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 23.15</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;15 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>13&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M149.87,-85.94C135.1,-76.12 118.82,-65.31 104.21,-55.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.08,-52.65 95.82,-50.03 102.21,-58.48 106.08,-52.65\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244.42,-50C244.42,-50 148.86,-50 148.86,-50 142.86,-50 136.86,-44 136.86,-38 136.86,-38 136.86,-12 136.86,-12 136.86,-6 142.86,0 148.86,0 148.86,0 244.42,0 244.42,0 250.42,0 256.42,-6 256.42,-12 256.42,-12 256.42,-38 256.42,-38 256.42,-44 250.42,-50 244.42,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 137</text>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 19.05</text>\n",
       "<text text-anchor=\"middle\" x=\"196.64\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 14.86</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;16 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>13&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196.64,-85.94C196.64,-77.68 196.64,-68.72 196.64,-60.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"200.14,-60.03 196.64,-50.03 193.14,-60.03 200.14,-60.03\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M381.42,-50C381.42,-50 285.86,-50 285.86,-50 279.86,-50 273.86,-44 273.86,-38 273.86,-38 273.86,-12 273.86,-12 273.86,-6 279.86,0 285.86,0 285.86,0 381.42,0 381.42,0 387.42,0 393.42,-6 393.42,-12 393.42,-12 393.42,-38 393.42,-38 393.42,-44 387.42,-50 381.42,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 49</text>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 35.82</text>\n",
       "<text text-anchor=\"middle\" x=\"333.64\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 31.99</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;17 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>14&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M333.64,-85.94C333.64,-77.68 333.64,-68.72 333.64,-60.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"337.14,-60.03 333.64,-50.03 330.14,-60.03 337.14,-60.03\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M518.42,-50C518.42,-50 422.86,-50 422.86,-50 416.86,-50 410.86,-44 410.86,-38 410.86,-38 410.86,-12 410.86,-12 410.86,-6 416.86,0 422.86,0 422.86,0 518.42,0 518.42,0 524.42,0 530.42,-6 530.42,-12 530.42,-12 530.42,-38 530.42,-38 530.42,-44 524.42,-50 518.42,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"470.64\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">Samples = 24</text>\n",
       "<text text-anchor=\"middle\" x=\"470.64\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">Impurity = 38.69</text>\n",
       "<text text-anchor=\"middle\" x=\"470.64\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">Average y = 45.00</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;18 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>14&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M380.4,-85.94C395.18,-76.12 411.46,-65.31 426.07,-55.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"428.07,-58.48 434.46,-50.03 424.2,-52.65 428.07,-58.48\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1263e0150>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "X = boston_df.values[:,:-1]\n",
    "y = boston_df.values[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "boston_decision_tree = DecisionTree(\n",
    "    impurity='mse',\n",
    "    is_classifier=False,\n",
    "    max_depth=2)\n",
    "boston_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# For info or ansii tree\n",
    "# boston_decision_tree.tree.info()\n",
    "# boston_decision_tree.tree.print_tree()\n",
    "\n",
    "boston_feature_names = boston_data['feature_names']\n",
    "boston_decision_tree.render(feature_names=boston_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Decision tree accuracy on Boston data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (R2 score) = 73.73%\n"
     ]
    }
   ],
   "source": [
    "y_pred = boston_decision_tree.predict(X_test)\n",
    "test_acc = r2_score(y_test, y_pred)\n",
    "print(f'Test accuracy (R2 score) = {test_acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
